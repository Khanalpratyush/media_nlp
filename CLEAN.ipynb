{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce8955d-52e3-4276-9860-2f3a62fe206f",
   "metadata": {},
   "source": [
    "### Natural language media search\n",
    "### Goals & scope\n",
    "- Given one or many video/audio files and a natural-language query, return the most relevant segments with: start/end timestamps, transcript snippet, thumbnail(s), and a relevance score.\n",
    "- **MVP scope** : Single-machine prototype that can index and search a handful of videos (hours of content).\n",
    "- **Core capabilities** to learn: audio transcription and alignment, audio/visual/text embeddings, vector indexing (FAISS), multimodal retrieval & reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f5ab0bb0-8dd9-4d4a-a51a-e32817026def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# media_preprocessor.py\n",
    "import ffmpeg\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import math\n",
    "import uuid\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import subprocess  # <-- Added for ffprobe\n",
    "\n",
    "# Optional VAD dependency\n",
    "try:\n",
    "    import webrtcvad\n",
    "    import wave\n",
    "    _VAD_AVAILABLE = True\n",
    "except Exception:\n",
    "    _VAD_AVAILABLE = False\n",
    "    print(\"Warning: 'webrtcvad' not found. VAD segmentation will be disabled.\")\n",
    "\n",
    "\n",
    "class MediaPreprocessor:\n",
    "    def __init__(self,\n",
    "                 keyframe_interval: int = 5,\n",
    "                 audio_segment_length: int = 30,\n",
    "                 target_sample_rate: int = 16000,\n",
    "                 frame_size: Tuple[int, int] = (224, 224),\n",
    "                 temp_dir: str = \"./media_processed\",\n",
    "                 target_lufs: float = -16.0,\n",
    "                 use_vad: bool = True,           # <-- Default changed\n",
    "                 scene_detect: bool = True,      # <-- Default changed\n",
    "                 vad_aggressiveness: int = 2,    # <-- NEW: Configurable\n",
    "                 scene_threshold: float = 0.4,   # <-- NEW: Configurable\n",
    "                 verbose: bool = False           # <-- NEW: For logging\n",
    "                ):\n",
    "        \"\"\"\n",
    "        keyframe_interval: seconds between extracted keyframes (if scene_detect=False)\n",
    "        audio_segment_length: seconds per chunk (used only if use_vad=False)\n",
    "        target_sample_rate: e.g., 16000 for Whisper\n",
    "        frame_size: (width, height) for resizing keyframes (224,224)\n",
    "        temp_dir: root for all outputs (a per-file UUID subdir will be created)\n",
    "        target_lufs: target loudness in LUFS for loudnorm (default -16)\n",
    "        use_vad: if True, attempt VAD-based segmentation (requires webrtcvad)\n",
    "        scene_detect: if True, use ffprobe scene-change selection instead of fixed interval\n",
    "        vad_aggressiveness: VAD sensitivity (0=least, 3=most aggressive)\n",
    "        scene_threshold: Scene change sensitivity (0.0=every frame, 1.0=no frames)\n",
    "        verbose: If True, prints all ffmpeg/ffprobe command output\n",
    "        \"\"\"\n",
    "        self.keyframe_interval = int(keyframe_interval)\n",
    "        self.audio_segment_length = int(audio_segment_length)\n",
    "        self.target_sample_rate = int(target_sample_rate)\n",
    "        self.frame_size = frame_size\n",
    "        self.root_temp_dir = Path(temp_dir)\n",
    "        self.root_temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.target_lufs = float(target_lufs)\n",
    "        self.use_vad = bool(use_vad) and _VAD_AVAILABLE\n",
    "        self.scene_detect = bool(scene_detect)\n",
    "        \n",
    "        # --- NEWLY ADDED PARAMETERS ---\n",
    "        self.vad_aggressiveness = int(vad_aggressiveness)\n",
    "        self.scene_threshold = float(scene_threshold)\n",
    "        self.verbose = bool(verbose)\n",
    "\n",
    "        print(\"✅ MediaPreprocessor initialized:\")\n",
    "        print(f\"  - Keyframe interval: {self.keyframe_interval}s\")\n",
    "        print(f\"  - Audio segment length: {self.audio_segment_length}s\")\n",
    "        print(f\"  - Target sample rate: {self.target_sample_rate}Hz\")\n",
    "        print(f\"  - Frame size: {self.frame_size}\")\n",
    "        print(f\"  - Root temp directory: {self.root_temp_dir.resolve()}\")\n",
    "        print(f\"  - Target LUFS: {self.target_lufs}\")\n",
    "        print(f\"  - VAD enabled: {self.use_vad} (webrtcvad available: {_VAD_AVAILABLE})\")\n",
    "        if self.use_vad:\n",
    "            print(f\"    - VAD Aggressiveness: {self.vad_aggressiveness}\")\n",
    "        print(f\"  - Scene-detect keyframes: {self.scene_detect}\")\n",
    "        if self.scene_detect:\n",
    "            print(f\"    - Scene Threshold: {self.scene_threshold}\")\n",
    "        print(f\"  - Verbose logging: {self.verbose}\")\n",
    "\n",
    "    # --------------------\n",
    "    def _make_run_dir(self, file_path: Path) -> Path:\n",
    "        \"\"\"\n",
    "        Create a unique directory for processing this file to avoid collisions.\n",
    "        \"\"\"\n",
    "        uid = uuid.uuid4().hex[:8]\n",
    "        out_dir = self.root_temp_dir / f\"{file_path.stem}_{uid}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return out_dir\n",
    "\n",
    "    # --------------------\n",
    "    def _get_duration(self, file_path: Path) -> float:\n",
    "        probe = ffmpeg.probe(str(file_path))\n",
    "        return float(probe['format']['duration'])\n",
    "\n",
    "    # --------------------\n",
    "    def _extract_audio(self, file_path: Path, out_dir: Path, normalize: bool = True) -> Path:\n",
    "        \"\"\"\n",
    "        Extract audio as 16kHz mono PCM WAV (pcm_s16le).\n",
    "        Uses loudnorm single-pass if normalize=True.\n",
    "        \"\"\"\n",
    "        out_path = out_dir / f\"{file_path.stem}_audio.wav\"\n",
    "        stream = ffmpeg.input(str(file_path))\n",
    "\n",
    "        if normalize:\n",
    "            ffmpeg_stream = stream.filter('loudnorm', I=self.target_lufs, TP=-1.5, LRA=7)\n",
    "        else:\n",
    "            ffmpeg_stream = stream\n",
    "\n",
    "        try:\n",
    "            (\n",
    "                ffmpeg_stream\n",
    "                .output(str(out_path),\n",
    "                        format='wav',\n",
    "                        acodec='pcm_s16le',\n",
    "                        ac=1,  # mono\n",
    "                        ar=self.target_sample_rate)\n",
    "                .overwrite_output()\n",
    "                .run(quiet=(not self.verbose)) # <-- Use verbose flag\n",
    "            )\n",
    "        except ffmpeg.Error as e:\n",
    "            raise RuntimeError(f\"ffmpeg failed extracting audio: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "        return out_path\n",
    "\n",
    "    # --------------------\n",
    "    def _segment_audio_fixed(self, audio_path: Path, out_dir: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fixed-length segmentation using ffmpeg segment (deterministic).\n",
    "        Returns list of {path, start_sec, end_sec}\n",
    "        \"\"\"\n",
    "        print(f\"  Segmenting audio with fixed {self.audio_segment_length}s intervals...\")\n",
    "        duration = self._get_duration(audio_path)\n",
    "        segments = []\n",
    "        num_chunks = math.ceil(duration / self.audio_segment_length)\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start = i * self.audio_segment_length\n",
    "            seg_len = min(self.audio_segment_length, max(0.0, duration - start))\n",
    "            if seg_len < 1.0: # Skip tiny trailing segments\n",
    "                continue\n",
    "                \n",
    "            seg_name = f\"{audio_path.stem}_chunk_{i:04d}_{int(start)}s.wav\"\n",
    "            chunk_path = out_dir / seg_name\n",
    "\n",
    "            try:\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(str(audio_path), ss=start, t=seg_len)\n",
    "                    .output(str(chunk_path),\n",
    "                            format='wav',\n",
    "                            acodec='pcm_s16le',\n",
    "                            ac=1,\n",
    "                            ar=self.target_sample_rate)\n",
    "                    .overwrite_output()\n",
    "                    .run(quiet=(not self.verbose)) # <-- Use verbose flag\n",
    "                )\n",
    "            except ffmpeg.Error as e:\n",
    "                raise RuntimeError(f\"ffmpeg failed segmenting audio: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "            segments.append({\n",
    "                \"path\": str(chunk_path.resolve()),\n",
    "                \"start_sec\": float(start),\n",
    "                \"end_sec\": float(start + seg_len)\n",
    "            })\n",
    "        print(f\"    Created {len(segments)} fixed-length audio segments.\")\n",
    "        return segments\n",
    "\n",
    "    # --------------------\n",
    "    def _segment_audio_vad(self, audio_path: Path, out_dir: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        VAD-based segmentation using webrtcvad.\n",
    "        Produces speech-only chunks.\n",
    "        \"\"\"\n",
    "        if not _VAD_AVAILABLE:\n",
    "            print(\"  webrtcvad not available; falling back to fixed segmentation.\")\n",
    "            return self._segment_audio_fixed(audio_path, out_dir)\n",
    "        \n",
    "        print(f\"  Segmenting audio with VAD (Aggressiveness: {self.vad_aggressiveness})...\")\n",
    "\n",
    "        # read WAV\n",
    "        with wave.open(str(audio_path), 'rb') as wf:\n",
    "            sample_rate = wf.getframerate()\n",
    "            assert sample_rate == self.target_sample_rate, f\"VAD requires {self.target_sample_rate}Hz, but file is {sample_rate}Hz\"\n",
    "            assert wf.getnchannels() == 1, \"VAD expects mono WAV\"\n",
    "            width = wf.getsampwidth()\n",
    "            assert width == 2, \"VAD expects 16-bit PCM (2 bytes)\"\n",
    "            pcm = wf.readframes(wf.getnframes())\n",
    "\n",
    "        vad = webrtcvad.Vad(self.vad_aggressiveness) # <-- Use configurable param\n",
    "\n",
    "        # webrtcvad supports 10, 20, 30 ms frames\n",
    "        frame_ms = 30\n",
    "        bytes_per_frame = int(sample_rate * (frame_ms / 1000.0) * width)\n",
    "        frames = [pcm[i:i+bytes_per_frame] for i in range(0, len(pcm), bytes_per_frame)]\n",
    "\n",
    "        voiced_flags = []\n",
    "        for f in frames:\n",
    "            if len(f) < bytes_per_frame:\n",
    "                f = f.ljust(bytes_per_frame, b'\\0') # Pad last frame\n",
    "            try:\n",
    "                voiced_flags.append(vad.is_speech(f, sample_rate))\n",
    "            except Exception:\n",
    "                voiced_flags.append(False)\n",
    "\n",
    "        # group contiguous voiced frames\n",
    "        segments = []\n",
    "        i = 0\n",
    "        while i < len(voiced_flags):\n",
    "            if voiced_flags[i]:\n",
    "                start_frame = i\n",
    "                while i < len(voiced_flags) and voiced_flags[i]:\n",
    "                    i += 1\n",
    "                end_frame = i - 1\n",
    "                \n",
    "                # --- This logic is simplified to just save the raw bytes ---\n",
    "                # --- Re-encoding with ffmpeg is safer and more robust ---\n",
    "                start_time = start_frame * (frame_ms / 1000.0)\n",
    "                end_time = (end_frame + 1) * (frame_ms / 1000.0)\n",
    "                seg_len = end_time - start_time\n",
    "                \n",
    "                # Filter out very short segments\n",
    "                if seg_len < 0.5: # 500ms minimum\n",
    "                    continue\n",
    "\n",
    "                seg_name = f\"{audio_path.stem}_vad_{start_time:.3f}s_{end_time:.3f}s.wav\"\n",
    "                chunk_path = out_dir / seg_name\n",
    "                \n",
    "                try:\n",
    "                    (\n",
    "                        ffmpeg\n",
    "                        .input(str(audio_path), ss=start_time, t=seg_len)\n",
    "                        .output(str(chunk_path), format='wav', acodec='pcm_s16le', ac=1, ar=self.target_sample_rate)\n",
    "                        .overwrite_output()\n",
    "                        .run(quiet=(not self.verbose)) # <-- Use verbose flag\n",
    "                    )\n",
    "                except ffmpeg.Error as e:\n",
    "                    print(f\"    Warning: ffmpeg failed extracting VAD segment: {e.stderr.decode() if e.stderr else e}\")\n",
    "                    continue\n",
    "\n",
    "                segments.append({\"path\": str(chunk_path.resolve()),\n",
    "                                 \"start_sec\": float(start_time),\n",
    "                                 \"end_sec\": float(end_time)})\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        print(f\"    Found {len(segments)} voiced audio segments.\")\n",
    "        # if no voiced segments found, fallback to fixed\n",
    "        if len(segments) == 0:\n",
    "            print(\"    No voiced segments found, falling back to fixed intervals.\")\n",
    "            return self._segment_audio_fixed(audio_path, out_dir)\n",
    "        return segments\n",
    "\n",
    "    # --------------------\n",
    "    def _extract_keyframes(self, file_path: Path, out_dir: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract keyframes.\n",
    "        If scene_detect=True, uses ffprobe to find scene-changes.\n",
    "        Otherwise, extracts at fixed intervals.\n",
    "        \"\"\"\n",
    "        frames = []\n",
    "        \n",
    "        # --- CRITICAL BUG FIX: Re-implemented scene detection ---\n",
    "        if self.scene_detect:\n",
    "            print(f\"  Extracting keyframes via scene-detect (Threshold: {self.scene_threshold})...\")\n",
    "            \n",
    "            # Step 1: Use ffprobe to get the exact timestamps of scene changes\n",
    "            ffprobe_cmd = [\n",
    "                \"ffprobe\",\n",
    "                \"-v\", \"error\",\n",
    "                \"-f\", \"lavfi\",\n",
    "                \"-i\", f\"movie={str(file_path.resolve())},select='gt(scene,{self.scene_threshold})'\",\n",
    "                \"-show_frames\",\n",
    "                \"-show_entries\", \"frame=pkt_pts_time\",\n",
    "                \"-of\", \"csv=p=0\"\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                if self.verbose:\n",
    "                    print(f\"    Running ffprobe cmd: {' '.join(ffprobe_cmd)}\")\n",
    "                result = subprocess.run(ffprobe_cmd, capture_output=True, text=True, check=True)\n",
    "                timestamps = [float(t) for t in result.stdout.splitlines()]\n",
    "                print(f\"    Found {len(timestamps)} scene changes.\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ffprobe scene-detect failed: {e}. Falling back to fixed interval.\")\n",
    "                self.scene_detect = False # Disable for this run\n",
    "                return self._extract_keyframes(file_path, out_dir) # Recurse with fallback\n",
    "\n",
    "            # Step 2: Loop through timestamps and extract one frame at each\n",
    "            for idx, ts in enumerate(timestamps):\n",
    "                out_path = out_dir / f\"{file_path.stem}_scene_{idx:05d}_{ts:.3f}s.jpg\"\n",
    "                try:\n",
    "                    (\n",
    "                        ffmpeg\n",
    "                        .input(str(file_path), ss=ts) # Seek to the exact timestamp\n",
    "                        .output(str(out_path), \n",
    "                                vframes=1, # Extract exactly one frame\n",
    "                                q=2)       # High quality JPEG\n",
    "                        .filter(\"scale\", self.frame_size[0], self.frame_size[1])\n",
    "                        .overwrite_output()\n",
    "                        .run(quiet=(not self.verbose)) # <-- Use verbose flag\n",
    "                    )\n",
    "                    frames.append({\"path\": str(out_path.resolve()), \"timestamp\": ts})\n",
    "                except ffmpeg.Error as e:\n",
    "                    print(f\"    Warning: Failed to extract frame at {ts}s: {e.stderr.decode() if e.stderr else e}\")\n",
    "            \n",
    "            print(f\"    Successfully extracted {len(frames)} scene-change frames.\")\n",
    "            return frames\n",
    "\n",
    "        # --- This is the fallback \"Fixed interval\" logic ---\n",
    "        print(f\"  Extracting keyframes via fixed-interval ({self.keyframe_interval}s)...\")\n",
    "        out_pattern = str(out_dir / f\"{file_path.stem}_frame_%06d.jpg\")\n",
    "        try:\n",
    "            fps_value = 1.0 / max(1, self.keyframe_interval)\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(str(file_path))\n",
    "                .filter(\"fps\", fps=fps_value)\n",
    "                .filter(\"scale\", self.frame_size[0], self.frame_size[1])\n",
    "                .output(out_pattern, vsync=\"vfr\", format='image2', q=2)\n",
    "                .overwrite_output()\n",
    "                .run(quiet=(not self.verbose)) # <-- Use verbose flag\n",
    "            )\n",
    "        except ffmpeg.Error as e:\n",
    "            raise RuntimeError(f\"ffmpeg fixed-interval keyframe extraction failed: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "        frame_files = sorted(out_dir.glob(f\"{file_path.stem}_frame_*.jpg\"))\n",
    "        for idx, p in enumerate(frame_files):\n",
    "            timestamp = float(idx * self.keyframe_interval)\n",
    "            frames.append({\"path\": str(p.resolve()), \"timestamp\": timestamp})\n",
    "        \n",
    "        print(f\"    Extracted {len(frames)} fixed-interval frames.\")\n",
    "        return frames\n",
    "\n",
    "    # --------------------\n",
    "    def _process_video_file(self, file_path: Path) -> Dict:\n",
    "        run_dir = self._make_run_dir(file_path)\n",
    "        print(f\"Processing video -> working directory: {run_dir}\")\n",
    "\n",
    "        print(\"  Extracting normalized audio...\")\n",
    "        audio_path = self._extract_audio(file_path, out_dir=run_dir, normalize=True)\n",
    "        \n",
    "        print(\"  Segmenting audio...\")\n",
    "        if self.use_vad:\n",
    "            audio_segments = self._segment_audio_vad(audio_path, out_dir=run_dir)\n",
    "        else:\n",
    "            audio_segments = self._segment_audio_fixed(audio_path, out_dir=run_dir)\n",
    "\n",
    "        print(\"  Extracting keyframes...\")\n",
    "        keyframes = self._extract_keyframes(file_path, out_dir=run_dir)\n",
    "        duration = self._get_duration(file_path)\n",
    "\n",
    "        print(f\"✅ Video processing complete for: {file_path.name}\")\n",
    "        return {\n",
    "            \"file_type\": \"video\",\n",
    "            \"original_file\": str(file_path.resolve()),\n",
    "            \"working_dir\": str(run_dir.resolve()),\n",
    "            \"audio_segments\": audio_segments,\n",
    "            \"video_keyframes\": keyframes,\n",
    "            \"metadata\": {\n",
    "                \"duration\": duration,\n",
    "                \"frame_size\": self.frame_size,\n",
    "                \"sample_rate\": self.target_sample_rate\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # --------------------\n",
    "    def _process_audio_file(self, file_path: Path) -> Dict:\n",
    "        run_dir = self._make_run_dir(file_path)\n",
    "        print(f\"Processing audio -> working directory: {run_dir}\")\n",
    "\n",
    "        print(\"  Extracting normalized audio...\")\n",
    "        audio_path = self._extract_audio(file_path, out_dir=run_dir, normalize=True)\n",
    "        \n",
    "        print(\"  Segmenting audio...\")\n",
    "        if self.use_vad:\n",
    "            audio_segments = self._segment_audio_vad(audio_path, out_dir=run_dir)\n",
    "        else:\n",
    "            audio_segments = self._segment_audio_fixed(audio_path, out_dir=run_dir)\n",
    "\n",
    "        duration = self._get_duration(audio_path)\n",
    "        \n",
    "        print(f\"✅ Audio processing complete for: {file_path.name}\")\n",
    "        return {\n",
    "            \"file_Type\": \"audio\",\n",
    "            \"original_file\": str(file_path.resolve()),\n",
    "            \"working_dir\": str(run_dir.resolve()),\n",
    "            \"audio_segments\": audio_segments,\n",
    "            \"metadata\": {\n",
    "                \"duration\": duration,\n",
    "                \"sample_rate\": self.target_sample_rate\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # --------------------\n",
    "    def process_media_file(self, file_path: str) -> Dict:\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        # --- Expanded file extensions ---\n",
    "        video_exts = {'.mp4', '.mkv', '.mov', '.avi', '.webm', '.flv', '.wmv', '.mpeg', '.mpg', '.m4v', '.m2ts'}\n",
    "        audio_exts = {'.mp3', '.wav', '.flac', '.aac', '.m4a', '.ogg', '.opus', '.wma', '.aiff'}\n",
    "\n",
    "        ext = file_path.suffix.lower()\n",
    "        if ext in video_exts:\n",
    "            return self._process_video_file(file_path)\n",
    "        elif ext in audio_exts:\n",
    "            return self._process_audio_file(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {ext}. Supported video: {video_exts}, Supported audio: {audio_exts}\")\n",
    "\n",
    "    # --------------------\n",
    "    def cleanup_run_dir(self, run_dir: str):\n",
    "        \"\"\"\n",
    "        Remove a previous working directory if needed.\n",
    "        \"\"\"\n",
    "        p = Path(run_dir)\n",
    "        if p.exists() and p.is_dir():\n",
    "            shutil.rmtree(p)\n",
    "            print(f\"Removed working dir: {p}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a77264d0-4c35-4307-9c41-b9d7a3f25777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MediaPreprocessor initialized:\n",
      "  - Keyframe interval: 5s\n",
      "  - Audio segment length: 30s\n",
      "  - Target sample rate: 16000Hz\n",
      "  - Frame size: (224, 224)\n",
      "  - Root temp directory: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed\n",
      "  - Target LUFS: -16.0\n",
      "  - VAD enabled: False (webrtcvad available: True)\n",
      "  - Scene-detect keyframes: False\n",
      "  - Verbose logging: False\n",
      "Processing video -> working directory: media_processed/vid2_fcd1acd8\n",
      "  Extracting normalized audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Segmenting audio...\n",
      "  Segmenting audio with fixed 30s intervals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Created 32 fixed-length audio segments.\n",
      "  Extracting keyframes...\n",
      "  Extracting keyframes via fixed-interval (5s)...\n",
      "    Extracted 187 fixed-interval frames.\n",
      "✅ Video processing complete for: vid2.mp4\n",
      "{\n",
      "  \"file_type\": \"video\",\n",
      "  \"original_file\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/vid2.mp4\",\n",
      "  \"working_dir\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8\",\n",
      "  \"audio_segments\": [\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0000_0s.wav\",\n",
      "      \"start_sec\": 0.0,\n",
      "      \"end_sec\": 30.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0001_30s.wav\",\n",
      "      \"start_sec\": 30.0,\n",
      "      \"end_sec\": 60.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0002_60s.wav\",\n",
      "      \"start_sec\": 60.0,\n",
      "      \"end_sec\": 90.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0003_90s.wav\",\n",
      "      \"start_sec\": 90.0,\n",
      "      \"end_sec\": 120.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0004_120s.wav\",\n",
      "      \"start_sec\": 120.0,\n",
      "      \"end_sec\": 150.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0005_150s.wav\",\n",
      "      \"start_sec\": 150.0,\n",
      "      \"end_sec\": 180.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0006_180s.wav\",\n",
      "      \"start_sec\": 180.0,\n",
      "      \"end_sec\": 210.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0007_210s.wav\",\n",
      "      \"start_sec\": 210.0,\n",
      "      \"end_sec\": 240.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0008_240s.wav\",\n",
      "      \"start_sec\": 240.0,\n",
      "      \"end_sec\": 270.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0009_270s.wav\",\n",
      "      \"start_sec\": 270.0,\n",
      "      \"end_sec\": 300.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0010_300s.wav\",\n",
      "      \"start_sec\": 300.0,\n",
      "      \"end_sec\": 330.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0011_330s.wav\",\n",
      "      \"start_sec\": 330.0,\n",
      "      \"end_sec\": 360.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0012_360s.wav\",\n",
      "      \"start_sec\": 360.0,\n",
      "      \"end_sec\": 390.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0013_390s.wav\",\n",
      "      \"start_sec\": 390.0,\n",
      "      \"end_sec\": 420.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0014_420s.wav\",\n",
      "      \"start_sec\": 420.0,\n",
      "      \"end_sec\": 450.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0015_450s.wav\",\n",
      "      \"start_sec\": 450.0,\n",
      "      \"end_sec\": 480.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0016_480s.wav\",\n",
      "      \"start_sec\": 480.0,\n",
      "      \"end_sec\": 510.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0017_510s.wav\",\n",
      "      \"start_sec\": 510.0,\n",
      "      \"end_sec\": 540.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0018_540s.wav\",\n",
      "      \"start_sec\": 540.0,\n",
      "      \"end_sec\": 570.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0019_570s.wav\",\n",
      "      \"start_sec\": 570.0,\n",
      "      \"end_sec\": 600.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0020_600s.wav\",\n",
      "      \"start_sec\": 600.0,\n",
      "      \"end_sec\": 630.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0021_630s.wav\",\n",
      "      \"start_sec\": 630.0,\n",
      "      \"end_sec\": 660.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0022_660s.wav\",\n",
      "      \"start_sec\": 660.0,\n",
      "      \"end_sec\": 690.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0023_690s.wav\",\n",
      "      \"start_sec\": 690.0,\n",
      "      \"end_sec\": 720.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0024_720s.wav\",\n",
      "      \"start_sec\": 720.0,\n",
      "      \"end_sec\": 750.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0025_750s.wav\",\n",
      "      \"start_sec\": 750.0,\n",
      "      \"end_sec\": 780.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0026_780s.wav\",\n",
      "      \"start_sec\": 780.0,\n",
      "      \"end_sec\": 810.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0027_810s.wav\",\n",
      "      \"start_sec\": 810.0,\n",
      "      \"end_sec\": 840.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0028_840s.wav\",\n",
      "      \"start_sec\": 840.0,\n",
      "      \"end_sec\": 870.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0029_870s.wav\",\n",
      "      \"start_sec\": 870.0,\n",
      "      \"end_sec\": 900.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0030_900s.wav\",\n",
      "      \"start_sec\": 900.0,\n",
      "      \"end_sec\": 930.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0031_930s.wav\",\n",
      "      \"start_sec\": 930.0,\n",
      "      \"end_sec\": 932.884938\n",
      "    }\n",
      "  ],\n",
      "  \"video_keyframes\": [\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000001.jpg\",\n",
      "      \"timestamp\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000002.jpg\",\n",
      "      \"timestamp\": 5.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000003.jpg\",\n",
      "      \"timestamp\": 10.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000004.jpg\",\n",
      "      \"timestamp\": 15.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000005.jpg\",\n",
      "      \"timestamp\": 20.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000006.jpg\",\n",
      "      \"timestamp\": 25.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000007.jpg\",\n",
      "      \"timestamp\": 30.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000008.jpg\",\n",
      "      \"timestamp\": 35.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000009.jpg\",\n",
      "      \"timestamp\": 40.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000010.jpg\",\n",
      "      \"timestamp\": 45.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000011.jpg\",\n",
      "      \"timestamp\": 50.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000012.jpg\",\n",
      "      \"timestamp\": 55.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000013.jpg\",\n",
      "      \"timestamp\": 60.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000014.jpg\",\n",
      "      \"timestamp\": 65.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000015.jpg\",\n",
      "      \"timestamp\": 70.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000016.jpg\",\n",
      "      \"timestamp\": 75.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000017.jpg\",\n",
      "      \"timestamp\": 80.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000018.jpg\",\n",
      "      \"timestamp\": 85.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000019.jpg\",\n",
      "      \"timestamp\": 90.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000020.jpg\",\n",
      "      \"timestamp\": 95.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000021.jpg\",\n",
      "      \"timestamp\": 100.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000022.jpg\",\n",
      "      \"timestamp\": 105.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000023.jpg\",\n",
      "      \"timestamp\": 110.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000024.jpg\",\n",
      "      \"timestamp\": 115.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000025.jpg\",\n",
      "      \"timestamp\": 120.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000026.jpg\",\n",
      "      \"timestamp\": 125.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000027.jpg\",\n",
      "      \"timestamp\": 130.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000028.jpg\",\n",
      "      \"timestamp\": 135.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000029.jpg\",\n",
      "      \"timestamp\": 140.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000030.jpg\",\n",
      "      \"timestamp\": 145.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000031.jpg\",\n",
      "      \"timestamp\": 150.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000032.jpg\",\n",
      "      \"timestamp\": 155.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000033.jpg\",\n",
      "      \"timestamp\": 160.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000034.jpg\",\n",
      "      \"timestamp\": 165.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000035.jpg\",\n",
      "      \"timestamp\": 170.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000036.jpg\",\n",
      "      \"timestamp\": 175.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000037.jpg\",\n",
      "      \"timestamp\": 180.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000038.jpg\",\n",
      "      \"timestamp\": 185.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000039.jpg\",\n",
      "      \"timestamp\": 190.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000040.jpg\",\n",
      "      \"timestamp\": 195.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000041.jpg\",\n",
      "      \"timestamp\": 200.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000042.jpg\",\n",
      "      \"timestamp\": 205.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000043.jpg\",\n",
      "      \"timestamp\": 210.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000044.jpg\",\n",
      "      \"timestamp\": 215.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000045.jpg\",\n",
      "      \"timestamp\": 220.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000046.jpg\",\n",
      "      \"timestamp\": 225.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000047.jpg\",\n",
      "      \"timestamp\": 230.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000048.jpg\",\n",
      "      \"timestamp\": 235.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000049.jpg\",\n",
      "      \"timestamp\": 240.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000050.jpg\",\n",
      "      \"timestamp\": 245.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000051.jpg\",\n",
      "      \"timestamp\": 250.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000052.jpg\",\n",
      "      \"timestamp\": 255.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000053.jpg\",\n",
      "      \"timestamp\": 260.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000054.jpg\",\n",
      "      \"timestamp\": 265.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000055.jpg\",\n",
      "      \"timestamp\": 270.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000056.jpg\",\n",
      "      \"timestamp\": 275.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000057.jpg\",\n",
      "      \"timestamp\": 280.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000058.jpg\",\n",
      "      \"timestamp\": 285.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000059.jpg\",\n",
      "      \"timestamp\": 290.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000060.jpg\",\n",
      "      \"timestamp\": 295.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000061.jpg\",\n",
      "      \"timestamp\": 300.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000062.jpg\",\n",
      "      \"timestamp\": 305.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000063.jpg\",\n",
      "      \"timestamp\": 310.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000064.jpg\",\n",
      "      \"timestamp\": 315.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000065.jpg\",\n",
      "      \"timestamp\": 320.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000066.jpg\",\n",
      "      \"timestamp\": 325.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000067.jpg\",\n",
      "      \"timestamp\": 330.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000068.jpg\",\n",
      "      \"timestamp\": 335.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000069.jpg\",\n",
      "      \"timestamp\": 340.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000070.jpg\",\n",
      "      \"timestamp\": 345.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000071.jpg\",\n",
      "      \"timestamp\": 350.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000072.jpg\",\n",
      "      \"timestamp\": 355.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000073.jpg\",\n",
      "      \"timestamp\": 360.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000074.jpg\",\n",
      "      \"timestamp\": 365.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000075.jpg\",\n",
      "      \"timestamp\": 370.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000076.jpg\",\n",
      "      \"timestamp\": 375.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000077.jpg\",\n",
      "      \"timestamp\": 380.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000078.jpg\",\n",
      "      \"timestamp\": 385.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000079.jpg\",\n",
      "      \"timestamp\": 390.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000080.jpg\",\n",
      "      \"timestamp\": 395.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000081.jpg\",\n",
      "      \"timestamp\": 400.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000082.jpg\",\n",
      "      \"timestamp\": 405.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000083.jpg\",\n",
      "      \"timestamp\": 410.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000084.jpg\",\n",
      "      \"timestamp\": 415.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000085.jpg\",\n",
      "      \"timestamp\": 420.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000086.jpg\",\n",
      "      \"timestamp\": 425.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000087.jpg\",\n",
      "      \"timestamp\": 430.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000088.jpg\",\n",
      "      \"timestamp\": 435.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000089.jpg\",\n",
      "      \"timestamp\": 440.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000090.jpg\",\n",
      "      \"timestamp\": 445.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000091.jpg\",\n",
      "      \"timestamp\": 450.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000092.jpg\",\n",
      "      \"timestamp\": 455.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000093.jpg\",\n",
      "      \"timestamp\": 460.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000094.jpg\",\n",
      "      \"timestamp\": 465.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000095.jpg\",\n",
      "      \"timestamp\": 470.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000096.jpg\",\n",
      "      \"timestamp\": 475.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000097.jpg\",\n",
      "      \"timestamp\": 480.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000098.jpg\",\n",
      "      \"timestamp\": 485.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000099.jpg\",\n",
      "      \"timestamp\": 490.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000100.jpg\",\n",
      "      \"timestamp\": 495.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000101.jpg\",\n",
      "      \"timestamp\": 500.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000102.jpg\",\n",
      "      \"timestamp\": 505.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000103.jpg\",\n",
      "      \"timestamp\": 510.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000104.jpg\",\n",
      "      \"timestamp\": 515.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000105.jpg\",\n",
      "      \"timestamp\": 520.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000106.jpg\",\n",
      "      \"timestamp\": 525.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000107.jpg\",\n",
      "      \"timestamp\": 530.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000108.jpg\",\n",
      "      \"timestamp\": 535.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000109.jpg\",\n",
      "      \"timestamp\": 540.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000110.jpg\",\n",
      "      \"timestamp\": 545.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000111.jpg\",\n",
      "      \"timestamp\": 550.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000112.jpg\",\n",
      "      \"timestamp\": 555.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000113.jpg\",\n",
      "      \"timestamp\": 560.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000114.jpg\",\n",
      "      \"timestamp\": 565.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000115.jpg\",\n",
      "      \"timestamp\": 570.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000116.jpg\",\n",
      "      \"timestamp\": 575.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000117.jpg\",\n",
      "      \"timestamp\": 580.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000118.jpg\",\n",
      "      \"timestamp\": 585.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000119.jpg\",\n",
      "      \"timestamp\": 590.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000120.jpg\",\n",
      "      \"timestamp\": 595.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000121.jpg\",\n",
      "      \"timestamp\": 600.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000122.jpg\",\n",
      "      \"timestamp\": 605.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000123.jpg\",\n",
      "      \"timestamp\": 610.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000124.jpg\",\n",
      "      \"timestamp\": 615.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000125.jpg\",\n",
      "      \"timestamp\": 620.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000126.jpg\",\n",
      "      \"timestamp\": 625.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000127.jpg\",\n",
      "      \"timestamp\": 630.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000128.jpg\",\n",
      "      \"timestamp\": 635.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000129.jpg\",\n",
      "      \"timestamp\": 640.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000130.jpg\",\n",
      "      \"timestamp\": 645.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000131.jpg\",\n",
      "      \"timestamp\": 650.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000132.jpg\",\n",
      "      \"timestamp\": 655.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000133.jpg\",\n",
      "      \"timestamp\": 660.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000134.jpg\",\n",
      "      \"timestamp\": 665.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000135.jpg\",\n",
      "      \"timestamp\": 670.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000136.jpg\",\n",
      "      \"timestamp\": 675.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000137.jpg\",\n",
      "      \"timestamp\": 680.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000138.jpg\",\n",
      "      \"timestamp\": 685.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000139.jpg\",\n",
      "      \"timestamp\": 690.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000140.jpg\",\n",
      "      \"timestamp\": 695.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000141.jpg\",\n",
      "      \"timestamp\": 700.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000142.jpg\",\n",
      "      \"timestamp\": 705.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000143.jpg\",\n",
      "      \"timestamp\": 710.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000144.jpg\",\n",
      "      \"timestamp\": 715.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000145.jpg\",\n",
      "      \"timestamp\": 720.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000146.jpg\",\n",
      "      \"timestamp\": 725.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000147.jpg\",\n",
      "      \"timestamp\": 730.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000148.jpg\",\n",
      "      \"timestamp\": 735.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000149.jpg\",\n",
      "      \"timestamp\": 740.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000150.jpg\",\n",
      "      \"timestamp\": 745.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000151.jpg\",\n",
      "      \"timestamp\": 750.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000152.jpg\",\n",
      "      \"timestamp\": 755.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000153.jpg\",\n",
      "      \"timestamp\": 760.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000154.jpg\",\n",
      "      \"timestamp\": 765.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000155.jpg\",\n",
      "      \"timestamp\": 770.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000156.jpg\",\n",
      "      \"timestamp\": 775.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000157.jpg\",\n",
      "      \"timestamp\": 780.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000158.jpg\",\n",
      "      \"timestamp\": 785.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000159.jpg\",\n",
      "      \"timestamp\": 790.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000160.jpg\",\n",
      "      \"timestamp\": 795.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000161.jpg\",\n",
      "      \"timestamp\": 800.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000162.jpg\",\n",
      "      \"timestamp\": 805.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000163.jpg\",\n",
      "      \"timestamp\": 810.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000164.jpg\",\n",
      "      \"timestamp\": 815.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000165.jpg\",\n",
      "      \"timestamp\": 820.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000166.jpg\",\n",
      "      \"timestamp\": 825.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000167.jpg\",\n",
      "      \"timestamp\": 830.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000168.jpg\",\n",
      "      \"timestamp\": 835.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000169.jpg\",\n",
      "      \"timestamp\": 840.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000170.jpg\",\n",
      "      \"timestamp\": 845.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000171.jpg\",\n",
      "      \"timestamp\": 850.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000172.jpg\",\n",
      "      \"timestamp\": 855.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000173.jpg\",\n",
      "      \"timestamp\": 860.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000174.jpg\",\n",
      "      \"timestamp\": 865.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000175.jpg\",\n",
      "      \"timestamp\": 870.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000176.jpg\",\n",
      "      \"timestamp\": 875.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000177.jpg\",\n",
      "      \"timestamp\": 880.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000178.jpg\",\n",
      "      \"timestamp\": 885.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000179.jpg\",\n",
      "      \"timestamp\": 890.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000180.jpg\",\n",
      "      \"timestamp\": 895.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000181.jpg\",\n",
      "      \"timestamp\": 900.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000182.jpg\",\n",
      "      \"timestamp\": 905.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000183.jpg\",\n",
      "      \"timestamp\": 910.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000184.jpg\",\n",
      "      \"timestamp\": 915.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000185.jpg\",\n",
      "      \"timestamp\": 920.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000186.jpg\",\n",
      "      \"timestamp\": 925.0\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"/Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_frame_000187.jpg\",\n",
      "      \"timestamp\": 930.0\n",
      "    }\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"duration\": 932.918231,\n",
      "    \"frame_size\": [\n",
      "      224,\n",
      "      224\n",
      "    ],\n",
      "    \"sample_rate\": 16000\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# --- Fix ---\n",
    "# 1. Define your media file path directly\n",
    "my_media_file = \"vid2.mp4\"\n",
    "\n",
    "# 2. Initialize the preprocessor\n",
    "mp = MediaPreprocessor(use_vad=False, scene_detect=False)\n",
    "\n",
    "try:\n",
    "    # 3. Call the method with your path\n",
    "    result = mp.process_media_file(my_media_file)\n",
    "    json_str= json.dumps(result, indent=2)\n",
    "    print(json_str)\n",
    "    with open(\"result.json\", \"w\") as f:\n",
    "      f.write(json_str)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the file at: {my_media_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "954b5eee-8631-4059-9dbc-6beff889bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(result, indent=2)\n",
    "with open(\"sample.json\", \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec30ace3-8c71-437e-ab5c-ebf290048c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_media_data = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f52c3-6439-4fc9-b2f1-daa79bf19a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'processed_media_data' is defined and Whisper is available. Proceeding with transcription.\n",
      "✅ Using existing Whisper model.\n",
      "\n",
      "Starting sequential transcription...\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0000_0s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0000_0s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0001_30s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0001_30s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0002_60s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0002_60s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0003_90s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0003_90s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0004_120s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0004_120s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0005_150s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0005_150s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0006_180s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0006_180s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0007_210s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0007_210s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0008_240s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0008_240s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0009_270s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0009_270s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0010_300s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0010_300s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0011_330s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0011_330s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0012_360s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0012_360s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0013_390s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0013_390s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0014_420s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0014_420s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0015_450s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0015_450s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0016_480s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0016_480s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0017_510s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0017_510s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0018_540s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0018_540s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0019_570s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0019_570s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0020_600s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0020_600s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0021_630s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0021_630s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0022_660s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0022_660s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0023_690s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0023_690s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0024_720s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0024_720s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0025_750s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0025_750s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0026_780s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0026_780s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0027_810s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0027_810s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0028_840s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription successful for: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0028_840s.wav\n",
      "🎙️ Transcribing segment: /Users/pratyushkhanal/Desktop/seniorseminar/media_nlp/media_processed/vid2_fcd1acd8/vid2_audio_chunk_0029_870s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import concurrent.futures # Keep import in case we want to switch back easily\n",
    "import os\n",
    "\n",
    "import whisper\n",
    "# Proceed only if processed_media_data is available AND whisper is imported and valid\n",
    "if ('processed_media_data' in globals() and processed_media_data is not None ):\n",
    "    print(\"✅ 'processed_media_data' is defined and Whisper is available. Proceeding with transcription.\")\n",
    "\n",
    "    # 1️⃣ Load the Whisper model\n",
    "    # Use the loaded model from a previous cell if available, otherwise load it\n",
    "    # Use the imported whisper name\n",
    "    if 'whisper_model' not in globals() or whisper_model is None:\n",
    "         whisper_model = whisper.load_model(\"base\")  # you can also use \"small\", \"medium\", or \"large\"\n",
    "         print(\"✅ Whisper model loaded.\")\n",
    "    else:\n",
    "         print(\"✅ Using existing Whisper model.\")\n",
    "\n",
    "\n",
    "    # Define a function to transcribe a single segment (this function is still useful even without parallel execution)\n",
    "    def transcribe_segment(segment_data):\n",
    "        audio_path = segment_data[\"path\"]\n",
    "        print(f\"🎙️ Transcribing segment: {audio_path}\")\n",
    "        try:\n",
    "            # Transcribe with word timestamps (useful for alignment later)\n",
    "            # Use the transcribe method from the loaded whisper model\n",
    "            result = whisper_model.transcribe(audio_path, word_timestamps=True)\n",
    "\n",
    "            # Add a check for the expected result type\n",
    "            if isinstance(result, dict) and \"text\" in result:\n",
    "                print(f\"Transcription successful for: {audio_path}\")\n",
    "                segment_data[\"transcription\"] = result[\"text\"]\n",
    "                segment_data[\"word_timestamps\"] = result[\"segments\"]\n",
    "            else:\n",
    "                # Handle unexpected return type\n",
    "                error_message = f\"Unexpected transcription result type for {audio_path}: {type(result)}. Result: {result}\"\n",
    "                print(f\"Error: {error_message}\")\n",
    "                segment_data[\"transcription\"] = f\"Error: {error_message}\" # Store error message in transcription\n",
    "                segment_data[\"word_timestamps\"] = []\n",
    "\n",
    "            return segment_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error transcribing segment {audio_path}: {e}\")\n",
    "            segment_data[\"transcription\"] = f\"Error: {e}\" # Store exception message in transcription\n",
    "            segment_data[\"word_timestamps\"] = []\n",
    "            return segment_data\n",
    "\n",
    "\n",
    "    # 4️⃣ Transcribe each audio segment sequentially (removed parallel processing)\n",
    "    print(\"\\nStarting sequential transcription...\")\n",
    "    for segment in processed_media_data[\"audio_segments\"]:\n",
    "        transcribe_segment(segment) # Call the transcription function for each segment\n",
    "\n",
    "    print(\"\\n✅ Sequential transcription complete!\")\n",
    "\n",
    "    # 5️⃣ (Optional) Save all results as JSON\n",
    "    # Ensure working_dir exists in processed_media_data\n",
    "    if \"working_dir\" in processed_media_data:\n",
    "        output_json_path = processed_media_data[\"working_dir\"] + \"/asr_output.json\"\n",
    "        try:\n",
    "            with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(processed_media_data, f, indent=2)\n",
    "            print(f\"✅ Transcription results saved to: {output_json_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving transcription results to {output_json_path}: {e}\")\n",
    "    else:\n",
    "        print(\"Warning: 'working_dir' not found in processed_media_data. Skipping saving results.\")\n",
    "\n",
    "else:\n",
    "    if not whisper_available:\n",
    "        print(\"Whisper library is not available or does not have 'load_model'. Skipping transcription.\")\n",
    "    elif 'processed_media_data' not in globals() or processed_media_data is None:\n",
    "         print(\"'processed_media_data' is not defined or is None. Skipping transcription.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54587283-c447-4c8a-9a46-0bbd72733d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'processed_media_data' is defined and has audio segments\n",
    "if 'processed_media_data' in globals() and processed_media_data is not None and \"audio_segments\" in processed_media_data:\n",
    "    print(\"--- Transcriptions ---\")\n",
    "    # Iterate through audio segments and print the transcription\n",
    "    for i, segment in enumerate(processed_media_data[\"audio_segments\"]):\n",
    "        transcription = segment.get(\"transcription\", \"No transcription available\")\n",
    "        start_time = segment.get(\"start_sec\", \"N/A\")\n",
    "        end_time = segment.get(\"end_sec\", \"N/A\")\n",
    "        print(f\"Segment {i+1} ({start_time:.2f}s - {end_time:.2f}s): {transcription}\")\n",
    "    print(\"--- End of Transcriptions ---\")\n",
    "else:\n",
    "    print(\"'processed_media_data' is not defined or does not contain audio segments. Please run the preprocessing and transcription steps first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1ba37-456a-42ce-8e2a-9666d151d80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d10a9b47-df5b-4b9b-80c5-b16b8539aefa",
   "metadata": {},
   "source": [
    "Sentence Transformers to convert the transcript snippets into dense vector representations suitable for similarity search against a natural language query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f287a010-b0a0-406b-ac85-999126c0763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b7566d88344cb6965e025e09e80884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e671b53fb9e4bd5b3d6d8477b552ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485ec4fe84a640959d3aed4338cc7e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb1320b18954283b8534069022d9d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6374046d024ce6a5f96511b7a635e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec81ab700280428f8a7b449b87b59e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7bdd2b66984504b62ca23594cedd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7d2063c7e2416f8c872e1036af754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the pre-trained CLIP model\n",
    "model_name = \"openai/clip-vit-large-patch14\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889213c-ff02-4fe9-9e7f-238020aad842",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "all_metadata = []\n",
    "\n",
    "# Get the embedding dimension from the model config\n",
    "embed_dim = clip_model.config.text_config.hidden_size #\n",
    "\n",
    "# --- 1. Embed Text Transcriptions ---\n",
    "print(\"Embedding text transcriptions...\")\n",
    "for segment in processed_media_data[\"audio_segments\"]:\n",
    "    transcription = segment.get(\"transcription\", \"\")\n",
    "    if not transcription or transcription.startswith(\"Error:\"):\n",
    "        continue\n",
    "\n",
    "    # Process and embed the text\n",
    "    inputs = processor(text=transcription, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.get_text_features(**inputs)\n",
    "    \n",
    "    # Normalize and store\n",
    "    text_vector = text_features.cpu().numpy().astype('float32')\n",
    "    faiss.normalize_L2(text_vector) # Normalize for FAISS L2 search\n",
    "    all_vectors.append(text_vector)\n",
    "    all_metadata.append({\n",
    "        \"type\": \"text\",\n",
    "        \"content\": transcription,\n",
    "        \"start_sec\": segment[\"start_sec\"],\n",
    "        \"end_sec\": segment[\"end_sec\"]\n",
    "    })\n",
    "\n",
    "# --- 2. Embed Video Keyframes ---\n",
    "print(\"Embedding video keyframes...\")\n",
    "for frame in processed_media_data[\"video_keyframes\"]:\n",
    "    try:\n",
    "        image = Image.open(frame[\"path\"])\n",
    "        \n",
    "        # Process and embed the image\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.get_image_features(**inputs)\n",
    "        \n",
    "        # Normalize and store\n",
    "        image_vector = image_features.cpu().numpy().astype('float32')\n",
    "        faiss.normalize_L2(image_vector)\n",
    "        all_vectors.append(image_vector)\n",
    "        all_metadata.append({\n",
    "            \"type\": \"image\",\n",
    "            \"path\": frame[\"path\"],\n",
    "            \"timestamp\": frame[\"timestamp\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {frame['path']}: {e}\")\n",
    "\n",
    "# --- 3. Embed Audio Segments (as Spectrograms) ---\n",
    "print(\"Embedding audio spectrograms...\")\n",
    "for segment in processed_media_data[\"audio_segments\"]:\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(segment[\"path\"], sr=16000) # Use sample rate from metadata if needed\n",
    "        \n",
    "        # Create a Mel spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        # Normalize and convert to 3-channel PIL Image (to mimic RGB)\n",
    "        S_norm = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "        S_img_array = (S_norm * 255).astype(np.uint8)\n",
    "        S_pil = Image.fromarray(S_img_array).convert(\"RGB\")\n",
    "        \n",
    "        # Process and embed the spectrogram *as an image*\n",
    "        inputs = processor(images=S_pil, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            audio_features = clip_model.get_image_features(**inputs)\n",
    "        \n",
    "        # Normalize and store\n",
    "        audio_vector = audio_features.cpu().numpy().astype('float32')\n",
    "        faiss.normalize_L2(audio_vector)\n",
    "        all_vectors.append(audio_vector)\n",
    "        all_metadata.append({\n",
    "            \"type\": \"audio\",\n",
    "            \"path\": segment[\"path\"],\n",
    "            \"start_sec\": segment[\"start_sec\"],\n",
    "            \"end_sec\": segment[\"end_sec\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio {segment['path']}: {e}\")\n",
    "\n",
    "print(f\"Total assets indexed: {len(all_vectors)}\")\n",
    "\n",
    "# Stack all vectors into a single NumPy array\n",
    "index_vectors = np.vstack(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861bbd5-3074-419b-b947-b19a52099753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c45b2c-62fb-484d-9a7a-7d19fced73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS index\n",
    "# IndexFlatL2 uses L2 distance (Euclidean)\n",
    "# Since we normalized our vectors, L2 distance is equivalent to cosine similarity, which is what CLIP uses.\n",
    "index = faiss.IndexFlatL2(embed_dim)\n",
    "\n",
    "# Add all our vectors to the index\n",
    "index.add(index_vectors)\n",
    "\n",
    "print(f\"FAISS index built with {index.ntotal} vectors.\")\n",
    "\n",
    "# You can save the index and metadata for later\n",
    "# faiss.write_index(index, \"my_video.index\")\n",
    "# with open(\"my_video_metadata.json\", \"w\") as f:\n",
    "#    json.dump(all_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174acbe9-0ffe-4311-8bb4-7814692b0dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e942ef-2516-402b-9f77-21a04e6ece06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from IPython.display import display, HTML, Video\n",
    "\n",
    "# --- Make sure all your previous imports are loaded ---\n",
    "# import torch\n",
    "# from transformers import CLIPProcessor, CLIPModel\n",
    "# from PIL import Image\n",
    "# import librosa\n",
    "# import numpy as np\n",
    "# import faiss\n",
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bf39f-fd01-4ba3-ad65-dcc1b8a8c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_video(text_query, k=5):\n",
    "    \"\"\"\n",
    "    Embeds a text query, searches the FAISS index, and returns the top k results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSearching for: '{text_query}'\")\n",
    "    \n",
    "    # 1. Embed the text query\n",
    "    inputs = clip_processor(text=text_query, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        query_features = clip_model.get_text_features(**inputs)\n",
    "    \n",
    "    # 2. Normalize the query vector\n",
    "    query_vector = query_features.cpu().numpy().astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    \n",
    "    # 3. Search the FAISS index\n",
    "    D, I = index.search(query_vector, k)\n",
    "    \n",
    "    # 4. Package up the results\n",
    "    results = []\n",
    "    print(\"Top results found. Generating clips...\")\n",
    "    for i in range(k):\n",
    "        result_index = I[0][i]\n",
    "        result_metadata = all_metadata[result_index]\n",
    "        distance = D[0][i]\n",
    "        results.append({\n",
    "            \"rank\": i + 1,\n",
    "            \"metadata\": result_metadata,\n",
    "            \"distance\": distance\n",
    "        })\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53788689-64f7-4fca-84d7-5f1696fdd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results_with_clips(results, original_video_path, working_dir, clip_duration=5):\n",
    "    \"\"\"\n",
    "    Generates and displays search results with embedded video clips.\n",
    "    \n",
    "    Assumes 'ffmpeg' is installed and accessible in your system's PATH.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We will build a single HTML string to display all results\n",
    "    html_output = \"<div>\"\n",
    "    \n",
    "    for res in results:\n",
    "        metadata = res[\"metadata\"]\n",
    "        distance = res[\"distance\"]\n",
    "        rank = res[\"rank\"]\n",
    "        \n",
    "        # --- 1. Determine Timeframe & Content ---\n",
    "        content_info = \"\"\n",
    "        if metadata[\"type\"] == \"text\" or metadata[\"type\"] == \"audio\":\n",
    "            start_sec = metadata[\"start_sec\"]\n",
    "            duration = metadata[\"end_sec\"] - metadata[\"start_sec\"]\n",
    "            content_info = f\"<b>[{metadata['type'].upper()}]</b> at {start_sec:.2f}s\"\n",
    "            if metadata['type'] == 'text':\n",
    "                content_info += f\": '<i>{metadata['content']}</i>'\"\n",
    "        \n",
    "        elif metadata[\"type\"] == \"image\":\n",
    "            # For an image, create a clip centered on the timestamp\n",
    "            start_sec = max(0, metadata[\"timestamp\"] - (clip_duration / 2))\n",
    "            duration = clip_duration\n",
    "            content_info = f\"<b>[IMAGE]</b> at {metadata['timestamp']:.2f}s (Source frame: {metadata['path']})\"\n",
    "        \n",
    "        # --- 2. Generate the Clip using FFmpeg ---\n",
    "        clip_filename = f\"search_result_rank_{rank}.mp4\"\n",
    "        clip_output_path = os.path.join(working_dir, clip_filename)\n",
    "        \n",
    "        # FFmpeg command:\n",
    "        # -y: Overwrite output file\n",
    "        # -ss: Seek to start time\n",
    "        # -i: Input file\n",
    "        # -t: Duration of the clip\n",
    "        # -c:v libx264: Re-encode video (safer for clips)\n",
    "        # -preset ultrafast: Encode very quickly\n",
    "        # -c:a aac: Re-encode audio\n",
    "        # -vf \"scale=480:-1\": Resize to 480px width, maintain aspect ratio\n",
    "        ffmpeg_command = (\n",
    "            f\"ffmpeg -y -ss {start_sec} -i \\\"{original_video_path}\\\" \"\n",
    "            f\"-t {duration} -c:v libx264 -preset ultrafast -c:a aac -vf \\\"scale=480:-1\\\" \"\n",
    "            f\"\\\"{clip_output_path}\\\"\"\n",
    "        )\n",
    "        \n",
    "        video_html = \"\"\n",
    "        try:\n",
    "            # Run the command (silence output with >/dev/null 2>&1)\n",
    "            os.system(f\"{ffmpeg_command} >/dev/null 2>&1\")\n",
    "            \n",
    "            # --- 3. Embed Video using Base64 ---\n",
    "            # This is robust and works well in all notebooks\n",
    "            with open(clip_output_path, \"rb\") as f:\n",
    "                video_data = f.read()\n",
    "            video_base64 = base64.b64encode(video_data).decode(\"utf-8\")\n",
    "            video_src = f\"data:video/mp4;base64,{video_base64}\"\n",
    "            \n",
    "            video_html = f'<video controls width=\"480\" src=\"{video_src}\" type=\"video/mp4\">Your browser does not support the video tag.</video>'\n",
    "            \n",
    "        except Exception as e:\n",
    "            video_html = f\"<p>Error generating video clip: {e}</p>\"\n",
    "\n",
    "        # --- 4. Build HTML for this result ---\n",
    "        html_output += f\"\"\"\n",
    "        <div style=\"border: 1px solid #ccc; border-radius: 8px; padding: 16px; margin-bottom: 16px; display: flex; align-items: top; flex-wrap: wrap; background-color: #f9f9f9;\">\n",
    "            <div style=\"flex: 1; min-width: 300px; padding-right: 16px;\">\n",
    "                <h3 style=\"margin-top:0;\">Rank {rank} (Distance: {distance:.4f})</h3>\n",
    "                <p>{content_info}</p>\n",
    "            </div>\n",
    "            <div style=\"flex-shrink: 0;\">\n",
    "                {video_html}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    \n",
    "    # Display the final combined HTML\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b92d1-0468-419b-9579-c1b18a09747c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7df2ac-ebd4-457e-94dd-7a987df7055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load your processed_media_data first ---\n",
    "# (Assuming 'processed_media_data' is loaded from your JSON file)\n",
    "# with open(\"path/to/your/asr_output.json\", \"r\") as f:\n",
    "#     processed_media_data = json.load(f)\n",
    "\n",
    "# Get the two paths we need from your main data object\n",
    "original_video_path = processed_media_data[\"original_file\"]\n",
    "working_dir = processed_media_data[\"working_dir\"]\n",
    "\n",
    "# --- 1. Run the search ---\n",
    "query = \"people falling\"\n",
    "search_results = search_video(query, k=5)\n",
    "# --- Try it out! ---\n",
    "\n",
    "# --- 2. Display results with clips ---\n",
    "display_search_results_with_clips(search_results, original_video_path, working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c17dfb24-291c-486a-9a91-3a36ee45f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'boooooom'\n",
      "Top results found. Generating clips...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'rank': 1,\n",
       "  'metadata': {'type': 'text',\n",
       "   'content': \" just as Sunday's was and so far touch would be. It's not been any dastardly, feel dastardly challenges. I'm not saying there's not going to be masherano on the ball plays it forward chabby in space turns plays inside doing the yesterday's seat back from and roads in the yesterday. Be gay now. Pedaling space on the full side. Come and tell us looking but I'm not sure you want to give pedal of that much space.\",\n",
       "   'start_sec': 1560.0,\n",
       "   'end_sec': 1590.0},\n",
       "  'distance': 0.5497296},\n",
       " {'rank': 2,\n",
       "  'metadata': {'type': 'text',\n",
       "   'content': \" the first book in the evening. Kiddia there. It's also five Sunday. Oh, and it was the wonderful board forward there. I think there's Buschets. Clips it through for Pedro. They're beating again. I think it's going to be a\",\n",
       "   'start_sec': 1860.0,\n",
       "   'end_sec': 1890.0},\n",
       "  'distance': 0.5507071},\n",
       " {'rank': 3,\n",
       "  'metadata': {'type': 'text',\n",
       "   'content': \" It's always the danger of course we saw that weekend Leo Messi is not really doing too much and then boom He strikes and then what then he strikes Little sounds of that Oh, it goes boom a boy putt does not look boom I don't know what I wanted to do a boy putt sound I don't know what sound I'm bipolar so the he seems I'll leave that one with here too you can practice up on our home\",\n",
       "   'start_sec': 2280.0,\n",
       "   'end_sec': 2310.0},\n",
       "  'distance': 0.5520489},\n",
       " {'rank': 4,\n",
       "  'metadata': {'type': 'text',\n",
       "   'content': \" out there's no doubt about the challenge that led to his book in the head of watch this. He's really. He just comes right across. PK and slap somewhere in the face. PK is OK to continue. It was a deal now. Get the ball off to the fall side. Ronaldo. Was peppy in the attack. Oh, well cut out by Daniel. There's Chabby and Lonzo. Keeps the.\",\n",
       "   'start_sec': 4380.0,\n",
       "   'end_sec': 4410.0},\n",
       "  'distance': 0.55514896},\n",
       " {'rank': 5,\n",
       "  'metadata': {'type': 'text',\n",
       "   'content': ' フェ будете f and do a drink first of.',\n",
       "   'start_sec': 3780.0,\n",
       "   'end_sec': 3810.0},\n",
       "  'distance': 0.5924648}]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_video(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88376103-11e1-43c1-b721-d82d5e305af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c44e46-3d45-4f00-9b15-f2f60330c9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2447c-76d9-4684-8bd2-112a877746a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22bb271-b4e1-4db7-a8d5-9eea1f7ac2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8090b04-ae44-4398-9778-bb0a3f99f41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d98d15-bebf-4827-a06f-0f4d8ab3e8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4bbf2-7561-4c35-9552-bff6ae9c8e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6178f-6483-425d-a86a-f7dd6f028ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a1c7a-61dc-41ab-bfae-d4991406f926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18f54f-8556-4e07-8e82-0c0e69eec387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b6695-c27c-4132-b9f9-32f854ac3bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713926f-4e7f-4c5d-a3e4-8afda551b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5adcb-ae69-40a1-9a87-1a03f48b1cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44332f-671a-4184-9189-cb745f4e4b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf8563-bad1-47c0-932a-b01d56324d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62fbbe2-b4bd-4b09-bb9f-1b686c51a3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3f587-cb1e-491a-bf43-b53f1984b9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53d5b5-d3e7-4cd1-87f3-0db4f8a1168c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da63159-7587-4e89-8152-f15612ab3280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62616e-7807-4ad2-9e2d-0c7af4abb263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b14e0-393c-4a2e-8e17-09fb8cae0a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
