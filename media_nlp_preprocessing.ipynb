{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05664f32-480c-4bf3-8d5e-852949869c9c",
   "metadata": {},
   "source": [
    "### Natural language media search\n",
    "### Goals & scope\n",
    "- Given one or many video/audio files and a natural-language query, return the most relevant segments with: start/end timestamps, transcript snippet, thumbnail(s), and a relevance score.\n",
    "- **MVP scope** : Single-machine prototype that can index and search a handful of videos (hours of content).\n",
    "- **Core capabilities** to learn: audio transcription and alignment, audio/visual/text embeddings, vector indexing (FAISS), multimodal retrieval & reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3376b-7b8f-4392-9424-f2a249c83eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef9d9c-81bc-4a85-a1a2-f77ec1870d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62127c-af17-403f-af00-e054fd6fe789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5a54d6-dbda-4e73-988b-b770aa8675c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# media_preprocessor.py\n",
    "import ffmpeg\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import math\n",
    "import uuid\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Optional VAD dependency\n",
    "try:\n",
    "    import webrtcvad\n",
    "    import wave\n",
    "    _VAD_AVAILABLE = True\n",
    "except Exception:\n",
    "    _VAD_AVAILABLE = False\n",
    "\n",
    "class MediaPreprocessor:\n",
    "    def __init__(self,\n",
    "                 keyframe_interval: int = 5,\n",
    "                 audio_segment_length: int = 30,\n",
    "                 target_sample_rate: int = 16000,\n",
    "                 frame_size: Tuple[int, int] = (224, 224),\n",
    "                 temp_dir: str = \"./media_processed\",\n",
    "                 target_lufs: float = -16.0,\n",
    "                 use_vad: bool = False,\n",
    "                 scene_detect: bool = False):\n",
    "        \"\"\"\n",
    "        keyframe_interval: seconds between extracted keyframes (if scene_detect=False)\n",
    "        audio_segment_length: seconds per chunk (used only if use_vad=False)\n",
    "        target_sample_rate: e.g., 16000 for Whisper\n",
    "        frame_size: (width, height) for resizing keyframes (224,224)\n",
    "        temp_dir: root for all outputs (a per-file UUID subdir will be created)\n",
    "        target_lufs: target loudness in LUFS for loudnorm (default -16)\n",
    "        use_vad: if True, attempt VAD-based segmentation (requires webrtcvad)\n",
    "        scene_detect: if True, use ffmpeg scene-change selection instead of fixed interval\n",
    "        \"\"\"\n",
    "        self.keyframe_interval = int(keyframe_interval)\n",
    "        self.audio_segment_length = int(audio_segment_length)\n",
    "        self.target_sample_rate = int(target_sample_rate)\n",
    "        self.frame_size = frame_size\n",
    "        self.root_temp_dir = Path(temp_dir)\n",
    "        self.root_temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.target_lufs = float(target_lufs)\n",
    "        self.use_vad = bool(use_vad) and _VAD_AVAILABLE\n",
    "        self.scene_detect = bool(scene_detect)\n",
    "\n",
    "        print(\"âœ… MediaPreprocessor initialized:\")\n",
    "        print(f\"  - Keyframe interval: {self.keyframe_interval}s\")\n",
    "        print(f\"  - Audio segment length: {self.audio_segment_length}s\")\n",
    "        print(f\"  - Target sample rate: {self.target_sample_rate}Hz\")\n",
    "        print(f\"  - Frame size: {self.frame_size}\")\n",
    "        print(f\"  - Root temp directory: {self.root_temp_dir.resolve()}\")\n",
    "        print(f\"  - Target LUFS: {self.target_lufs}\")\n",
    "        print(f\"  - VAD enabled: {self.use_vad} (webrtcvad available: {_VAD_AVAILABLE})\")\n",
    "        print(f\"  - Scene-detect keyframes: {self.scene_detect}\")\n",
    "\n",
    "    # --------------------\n",
    "    def _make_run_dir(self, file_path: Path) -> Path:\n",
    "        \"\"\"\n",
    "        Create a unique directory for processing this file to avoid collisions.\n",
    "        \"\"\"\n",
    "        uid = uuid.uuid4().hex[:8]\n",
    "        out_dir = self.root_temp_dir / f\"{file_path.stem}_{uid}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return out_dir\n",
    "\n",
    "    # --------------------\n",
    "    def _get_duration(self, file_path: Path) -> float:\n",
    "        probe = ffmpeg.probe(str(file_path))\n",
    "        return float(probe['format']['duration'])\n",
    "\n",
    "    # --------------------\n",
    "    def _extract_audio(self, file_path: Path, out_dir: Path, normalize: bool = True) -> Path:\n",
    "        \"\"\"\n",
    "        Extract audio as 16kHz mono PCM WAV (pcm_s16le).\n",
    "        Uses loudnorm single-pass if normalize=True. For better accuracy you could\n",
    "        run 2-pass loudnorm (analyze then apply measured params).\n",
    "        \"\"\"\n",
    "        out_path = out_dir / f\"{file_path.stem}_audio.wav\"\n",
    "\n",
    "        stream = ffmpeg.input(str(file_path))\n",
    "\n",
    "        if normalize:\n",
    "            # Simple single-pass loudnorm. For best fidelity: run two-pass approach (analyze, then apply).\n",
    "            ffmpeg_stream = stream.filter('loudnorm', I=self.target_lufs, TP=-1.5, LRA=7)\n",
    "        else:\n",
    "            ffmpeg_stream = stream\n",
    "\n",
    "        try:\n",
    "            (\n",
    "                ffmpeg_stream\n",
    "                .output(str(out_path),\n",
    "                        format='wav',\n",
    "                        acodec='pcm_s16le',\n",
    "                        ac=1,  # mono\n",
    "                        ar=self.target_sample_rate)\n",
    "                .overwrite_output()\n",
    "                .run(quiet=True)\n",
    "            )\n",
    "        except ffmpeg.Error as e:\n",
    "            # include stderr for debugging\n",
    "            raise RuntimeError(f\"ffmpeg failed extracting audio: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "        return out_path\n",
    "\n",
    "    # --------------------\n",
    "    def _segment_audio_fixed(self, audio_path: Path, out_dir: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fixed-length segmentation using ffmpeg segment (deterministic).\n",
    "        Returns list of {path, start_sec, end_sec}\n",
    "        \"\"\"\n",
    "        duration = self._get_duration(audio_path)\n",
    "        segments = []\n",
    "        num_chunks = math.ceil(duration / self.audio_segment_length)\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start = i * self.audio_segment_length\n",
    "            seg_len = min(self.audio_segment_length, max(0.0, duration - start))\n",
    "            start_str = f\"{start:.3f}\"\n",
    "            seg_name = f\"{audio_path.stem}_chunk_{i:04d}_{int(start)}s.wav\"\n",
    "            chunk_path = out_dir / seg_name\n",
    "\n",
    "            try:\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(str(audio_path), ss=start, t=seg_len)\n",
    "                    .output(str(chunk_path),\n",
    "                            format='wav',\n",
    "                            acodec='pcm_s16le',\n",
    "                            ac=1,\n",
    "                            ar=self.target_sample_rate)\n",
    "                    .overwrite_output()\n",
    "                    .run(quiet=True)\n",
    "                )\n",
    "            except ffmpeg.Error as e:\n",
    "                raise RuntimeError(f\"ffmpeg failed segmenting audio: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "            segments.append({\n",
    "                \"path\": str(chunk_path),\n",
    "                \"start_sec\": float(start),\n",
    "                \"end_sec\": float(start + seg_len)\n",
    "            })\n",
    "\n",
    "        return segments\n",
    "\n",
    "    # --------------------\n",
    "    def _segment_audio_vad(self, audio_path: Path, out_dir: Path, aggressiveness: int = 2) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Very simple VAD-based segmentation using webrtcvad.\n",
    "        Produces speech-only chunks by grouping contiguous voiced frames.\n",
    "        Requirements: webrtcvad installed.\n",
    "        Note: This is a basic implementation and may need tuning for production.\n",
    "        \"\"\"\n",
    "        if not _VAD_AVAILABLE:\n",
    "            print(\"webrtcvad not available; falling back to fixed segmentation.\")\n",
    "            return self._segment_audio_fixed(audio_path, out_dir)\n",
    "\n",
    "        # read WAV\n",
    "        with wave.open(str(audio_path), 'rb') as wf:\n",
    "            sample_rate = wf.getframerate()\n",
    "            assert wf.getnchannels() == 1, \"VAD expects mono WAV\"\n",
    "            width = wf.getsampwidth()\n",
    "            pcm = wf.readframes(wf.getnframes())\n",
    "\n",
    "        vad = webrtcvad.Vad(aggressiveness)\n",
    "\n",
    "        # frame size in ms. webrtcvad supports 10,20,30\n",
    "        frame_ms = 30\n",
    "        bytes_per_frame = int(sample_rate * (frame_ms / 1000.0) * width)\n",
    "        frames = [pcm[i:i+bytes_per_frame] for i in range(0, len(pcm), bytes_per_frame)]\n",
    "\n",
    "        voiced_flags = [False] * len(frames)\n",
    "        for i, f in enumerate(frames):\n",
    "            if len(f) < bytes_per_frame:\n",
    "                # pad last frame\n",
    "                f = f.ljust(bytes_per_frame, b'\\0')\n",
    "            try:\n",
    "                voiced_flags[i] = vad.is_speech(f, sample_rate)\n",
    "            except Exception:\n",
    "                voiced_flags[i] = False\n",
    "\n",
    "        # group contiguous voiced frames\n",
    "        segments = []\n",
    "        i = 0\n",
    "        while i < len(voiced_flags):\n",
    "            if voiced_flags[i]:\n",
    "                start_frame = i\n",
    "                while i < len(voiced_flags) and voiced_flags[i]:\n",
    "                    i += 1\n",
    "                end_frame = i - 1\n",
    "                start_time = start_frame * (frame_ms / 1000.0)\n",
    "                end_time = (end_frame + 1) * (frame_ms / 1000.0)\n",
    "                seg_name = f\"{audio_path.stem}_vad_{int(start_time)}s_{int(end_time)}s.wav\"\n",
    "                chunk_path = out_dir / seg_name\n",
    "                seg_len = end_time - start_time\n",
    "                # extract segment with ffmpeg for robust encoding\n",
    "                try:\n",
    "                    (\n",
    "                        ffmpeg\n",
    "                        .input(str(audio_path), ss=start_time, t=seg_len)\n",
    "                        .output(str(chunk_path), format='wav', acodec='pcm_s16le', ac=1, ar=self.target_sample_rate)\n",
    "                        .overwrite_output()\n",
    "                        .run(quiet=True)\n",
    "                    )\n",
    "                except ffmpeg.Error as e:\n",
    "                    raise RuntimeError(f\"ffmpeg failed extracting VAD segment: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "                segments.append({\"path\": str(chunk_path),\n",
    "                                 \"start_sec\": float(start_time),\n",
    "                                 \"end_sec\": float(end_time)})\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        # if no voiced segments found, fallback to fixed\n",
    "        if len(segments) == 0:\n",
    "            return self._segment_audio_fixed(audio_path, out_dir)\n",
    "        return segments\n",
    "\n",
    "    # --------------------\n",
    "    def _extract_keyframes(self, file_path: Path, out_dir: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract keyframes and produce list of {\"path\": str, \"timestamp\": float}.\n",
    "        If scene_detect=True, extract frames only at scene changes; otherwise extract\n",
    "        at fixed intervals (every keyframe_interval seconds).\n",
    "        \"\"\"\n",
    "        frames = []\n",
    "        if self.scene_detect:\n",
    "            # Use scene-change detection\n",
    "            out_pattern = str(out_dir / f\"{file_path.stem}_frame_scene_%04d.jpg\")\n",
    "            try:\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(str(file_path))\n",
    "                    .filter(\"select\", \"gt(scene,0.4)\")\n",
    "                    .filter(\"scale\", self.frame_size[0], self.frame_size[1])\n",
    "                    .output(out_pattern, vsync=\"vfr\", format='image2')\n",
    "                    .overwrite_output()\n",
    "                    .run(quiet=True)\n",
    "                )\n",
    "            except ffmpeg.Error as e:\n",
    "                raise RuntimeError(f\"ffmpeg scene-detect failed: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "            # No exact timestamps provided; we will estimate by probing each frame file via ffmpeg.probe (slow),\n",
    "            # or compute using ffmpeg select expression to include pts â€” for simplicity, estimate by reading\n",
    "            # the creation order and mapping approximate times using frame count * keyframe_interval as fallback.\n",
    "            frame_files = sorted(out_dir.glob(f\"{file_path.stem}_frame_scene_*.jpg\"))\n",
    "            # try to read pts via ffprobe per frame â€” expensive; fallback to index*interval\n",
    "            for idx, p in enumerate(frame_files):\n",
    "                frames.append({\"path\": str(p), \"timestamp\": float(idx * self.keyframe_interval)})\n",
    "            return frames\n",
    "\n",
    "        # Fixed interval\n",
    "        out_pattern = str(out_dir / f\"{file_path.stem}_frame_%06d.jpg\")\n",
    "        try:\n",
    "            # fps=1/N -> extract one frame every N seconds; ffmpeg expects fraction or float\n",
    "            fps_value = 1.0 / max(1, self.keyframe_interval)\n",
    "            (\n",
    "                ffmpeg\n",
    "                .input(str(file_path))\n",
    "                .filter(\"fps\", fps=fps_value)\n",
    "                .filter(\"scale\", self.frame_size[0], self.frame_size[1])\n",
    "                .output(out_pattern, vsync=\"vfr\", format='image2')\n",
    "                .overwrite_output()\n",
    "                .run(quiet=True)\n",
    "            )\n",
    "        except ffmpeg.Error as e:\n",
    "            raise RuntimeError(f\"ffmpeg fixed-interval keyframe extraction failed: {e.stderr.decode() if e.stderr else e}\") from e\n",
    "\n",
    "        frame_files = sorted(out_dir.glob(f\"{file_path.stem}_frame_*.jpg\"))\n",
    "        # map each frame to a timestamp: frame_index * keyframe_interval (approximate)\n",
    "        for idx, p in enumerate(frame_files):\n",
    "            timestamp = float(idx * self.keyframe_interval)\n",
    "            frames.append({\"path\": str(p), \"timestamp\": timestamp})\n",
    "\n",
    "        return frames\n",
    "\n",
    "    # --------------------\n",
    "    def _process_video_file(self, file_path: Path) -> Dict:\n",
    "        run_dir = self._make_run_dir(file_path)\n",
    "        print(f\"Processing video -> working directory: {run_dir}\")\n",
    "\n",
    "        audio_path = self._extract_audio(file_path, out_dir=run_dir, normalize=True)\n",
    "        if self.use_vad:\n",
    "            audio_segments = self._segment_audio_vad(audio_path, out_dir=run_dir)\n",
    "        else:\n",
    "            audio_segments = self._segment_audio_fixed(audio_path, out_dir=run_dir)\n",
    "\n",
    "        keyframes = self._extract_keyframes(file_path, out_dir=run_dir)\n",
    "        duration = self._get_duration(file_path)\n",
    "\n",
    "        return {\n",
    "            \"file_type\": \"video\",\n",
    "            \"original_file\": str(file_path.resolve()),\n",
    "            \"working_dir\": str(run_dir.resolve()),\n",
    "            \"audio_segments\": audio_segments,\n",
    "            \"video_keyframes\": keyframes,\n",
    "            \"metadata\": {\n",
    "                \"duration\": duration,\n",
    "                \"frame_size\": self.frame_size,\n",
    "                \"sample_rate\": self.target_sample_rate\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # --------------------\n",
    "    def _process_audio_file(self, file_path: Path) -> Dict:\n",
    "        run_dir = self._make_run_dir(file_path)\n",
    "        print(f\"Processing audio -> working directory: {run_dir}\")\n",
    "\n",
    "        audio_path = self._extract_audio(file_path, out_dir=run_dir, normalize=True)\n",
    "        if self.use_vad:\n",
    "            audio_segments = self._segment_audio_vad(audio_path, out_dir=run_dir)\n",
    "        else:\n",
    "            audio_segments = self._segment_audio_fixed(audio_path, out_dir=run_dir)\n",
    "\n",
    "        duration = self._get_duration(audio_path)\n",
    "        return {\n",
    "            \"file_type\": \"audio\",\n",
    "            \"original_file\": str(file_path.resolve()),\n",
    "            \"working_dir\": str(run_dir.resolve()),\n",
    "            \"audio_segments\": audio_segments,\n",
    "            \"metadata\": {\n",
    "                \"duration\": duration,\n",
    "                \"sample_rate\": self.target_sample_rate\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # --------------------\n",
    "    def process_media_file(self, file_path: str) -> Dict:\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        video_exts = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}\n",
    "        audio_exts = {'.wav', '.mp3', '.flac', '.aac', '.ogg', '.m4a'}\n",
    "\n",
    "        ext = file_path.suffix.lower()\n",
    "        if ext in video_exts:\n",
    "            return self._process_video_file(file_path)\n",
    "        elif ext in audio_exts:\n",
    "            return self._process_audio_file(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "\n",
    "    # --------------------\n",
    "    def cleanup_run_dir(self, run_dir: str):\n",
    "        \"\"\"\n",
    "        Remove a previous working directory if needed.\n",
    "        \"\"\"\n",
    "        p = Path(run_dir)\n",
    "        if p.exists() and p.is_dir():\n",
    "            shutil.rmtree(p)\n",
    "            print(f\"Removed working dir: {p}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Quick CLI test (runs when the file is executed directly)\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python media_preprocessor.py <path-to-media-file>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    mp = MediaPreprocessor(use_vad=False, scene_detect=False)\n",
    "    result = mp.process_media_file(sys.argv[1])\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192a452-dc13-4377-8e82-c4639f006570",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymediaprocessor = MediaPreprocessor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb78d3f-b25d-4e32-90b1-72586dcb0666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
